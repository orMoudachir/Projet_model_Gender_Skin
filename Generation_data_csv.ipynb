{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18430ca1-0349-4d72-8d97-ba55ededcff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1cefb05-f503-4b38-b7aa-2d91c5973855",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prédiction de nouvelles images: 100%|██| 10000/10000 [30:24<00:00,  5.48image/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification complète en 30m 24s\n"
     ]
    }
   ],
   "source": [
    "# Chemin des dossiers source et destination\n",
    "source_dir = \"/Users/mohameddiallo/Analyse-de-donnees-et-RL-inverse-pour-la-d-tection-de-biais/ProjetEmmanuelleClaeys/Academic_Dataset_by_Generated_Photos/generated.photos\"\n",
    "new_images_dir = \"/Users/mohameddiallo/Analyse-de-donnees-et-RL-inverse-pour-la-d-tection-de-biais/ProjetEmmanuelleClaeys/classification_verif\"\n",
    "\n",
    "# Charger le modèle PyTorch pré-entraîné\n",
    "model = torch.load(\"/Users/mohameddiallo/Analyse-de-donnees-et-RL-inverse-pour-la-d-tection-de-biais/ProjetEmmanuelleClaeys/code/best_model_resnet101.pth\")\n",
    "model.eval()\n",
    "\n",
    "# Transformation des images pour l'inférence\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Fonction pour classifier les nouvelles images\n",
    "def classify_new_images(source_dir, new_images_dir, model):\n",
    "    since = time.time()\n",
    "    # Liste des fichiers dans le dossier source\n",
    "    source_files = [f for f in os.listdir(source_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp'))]\n",
    "    \n",
    "    # Création du dossier pour les nouvelles images si nécessaire\n",
    "    if not os.path.exists(new_images_dir):\n",
    "        os.makedirs(new_images_dir)\n",
    "    \n",
    "    # Parcours des fichiers dans le dossier source\n",
    "    for file in tqdm(source_files, desc=\"Prédiction de nouvelles images\", unit=\"image\"):\n",
    "        # Charger l'image et effectuer la prédiction\n",
    "        image = Image.open(os.path.join(source_dir, file))\n",
    "        image_tensor = transform(image).unsqueeze(0)\n",
    "        output = model(image_tensor)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        \n",
    "        # Créer un sous-dossier pour la classe prédite si nécessaire\n",
    "        predicted_class_dir = os.path.join(new_images_dir, str(predicted.item()))\n",
    "        if not os.path.exists(predicted_class_dir):\n",
    "            os.makedirs(predicted_class_dir)\n",
    "        \n",
    "        # Déplacer l'image dans le sous-dossier de la classe prédite\n",
    "        shutil.move(os.path.join(source_dir, file), os.path.join(predicted_class_dir, file))\n",
    "    \n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Classification complète en {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "\n",
    "# Appel de la fonction\n",
    "classify_new_images(source_dir, new_images_dir, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd0091ee-59a9-460f-8ad7-429f491a97ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parcours des dossiers de couleur de peau: 100%|█| 5/5 [49:56<00:00, 599.25s/imag"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les informations ont été sauvegardées dans le fichier CSV.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Charger le modèle PyTorch pré-entraîné pour l'identification du genre\n",
    "genre_model = torch.load(\"best_model_Gender_class.pth\")\n",
    "genre_model.eval()\n",
    "\n",
    "# Transformation des images pour l'inférence\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Dossier contenant les images classées par couleur de peau\n",
    "base_dir = \"/Users/mohameddiallo/Analyse-de-donnees-et-RL-inverse-pour-la-d-tection-de-biais/ProjetEmmanuelleClaeys/classification_verif\"\n",
    "\n",
    "# Liste des dossiers (couleurs de peau)\n",
    "skin_color_folders = [folder for folder in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, folder))]\n",
    "\n",
    "# Liste pour stocker les informations à sauvegarder dans le CSV\n",
    "data = []\n",
    "\n",
    "# Parcours des dossiers de couleur de peau\n",
    "for skin_color_folder in tqdm(skin_color_folders, desc=\"Parcours des dossiers de couleur de peau\", unit=\"image\"): \n",
    "    # Chemin complet du dossier de couleur de peau\n",
    "    skin_color_path = os.path.join(base_dir, skin_color_folder)\n",
    "    \n",
    "    # Liste des fichiers (images) dans le dossier\n",
    "    image_files = [f for f in os.listdir(skin_color_path) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp'))]\n",
    "    \n",
    "    # Parcours des images dans le dossier\n",
    "    for image_file in image_files:\n",
    "        # Charger l'image\n",
    "        image = Image.open(os.path.join(skin_color_path, image_file))\n",
    "        # Prétraitement de l'image\n",
    "        image_tensor = transform(image).unsqueeze(0)\n",
    "        # Prédiction du genre\n",
    "        output = genre_model(image_tensor)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        \n",
    "        # Ajouter les informations à la liste de données\n",
    "        data.append({'image': image_file, 'skin_color': skin_color_folder, 'genre': predicted.item()})\n",
    "\n",
    "# Convertir la liste de données en DataFrame pandas\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Enregistrer le DataFrame dans un fichier CSV\n",
    "df.to_csv(\"informations_images.csv\", index=False)\n",
    "\n",
    "print(\"Les informations ont été sauvegardées dans le fichier CSV.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b11305-60e5-4151-a1f2-36ca57c99cd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
